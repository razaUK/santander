{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I rapidly prototyped several machine learning models (gradient boosting, Xgboost, random forests, logistic regression) and noted that gradient boosting achieved the best results. This notebook outlines a mechanism for training the model and generating outputs and should be seen as indicative  - but this is not final code (there is little in the way of checks on missing / incorrectly formatted data etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import GradientBoostingClassifier  \n",
    "from sklearn import cross_validation, metrics   \n",
    "from sklearn.grid_search import GridSearchCV   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the input and test files. Paths are hardcoded, and the files are assumed to be in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = pd.read_csv(\"train.csv\")\n",
    "evaluation_set = pd.read_csv(\"test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows for which the target is unknown.\n",
    "ml_dataset = ml_dataset[~ml_dataset['TARGET'].isnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values in predictors with column means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target in both the \n",
    "predictors = [x for x in ml_dataset.columns if x not in ['class_col']]\n",
    "for feature in predictors:\n",
    "    v = ml_dataset[feature].mean()\n",
    "    ml_dataset[feature] = ml_dataset[feature].fillna(v)\n",
    "    evaluation_set[feature] = evaluation_set[feature].fillna(v)\n",
    "    print('Imputed missing values in feature %s with value %s' % (feature, str(v)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model with *some* of the parameters tuned using grid search. With more time, some of the other variables could be tuned too. I also evaluated logistic regression, xgboost, SVM, NNs and random forests and got best results with gradient boosting (XGBoost had more variance during cross validation search, suggesting greater sensitivity to parameters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':list(range(3,18,3)), 'min_samples_leaf':list(range(3,15,3)), 'min_samples_split':list(range(2,502,50)),'n_estimators':list(range(20,81,10))}\n",
    "gsearch = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, max_features='sqrt',random_state=10), \n",
    "param_grid = params, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(ml_dataset[predictors],ml_dataset['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the final model and generate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalmodel = gsearch.best_estimator_.fit(ml_dataset[predictors],ml_dataset['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions (just to see things look okay) and probabilities [yhat]\n",
    "predictions = finalmodel.predict(evaluation_set[predictors])\n",
    "predprob = finalmodel.predict_proba(evaluation_set[predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(predprob, columns=['yhat'])\n",
    "results.to_csv(\"results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
